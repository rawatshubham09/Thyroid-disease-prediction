{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DataScience\\\\Thyroid-disease-prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Thyroid_Disease.constants import *\n",
    "from Thyroid_Disease.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH,\n",
    "            schema_filepath = SCHEMA_FILE_PATH ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path= config.data_path,\n",
    "        )\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Thyroid_Disease import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.data = pd.read_csv(config.data_path)\n",
    "\n",
    "    def train_test_split(self) -> None:\n",
    "\n",
    "\n",
    "        train, test = train_test_split(self.data,test_size=0.2, random_state= 42)\n",
    "\n",
    "        #saving train test as csv\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"),index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"),index = False)\n",
    "\n",
    "        logger.info(\"Splited data into test and train sets\")\n",
    "        logger.info(f\"train shape:{train.shape}\")\n",
    "        logger.info(f\"Test shape: {test.shape}\")\n",
    "\n",
    "        print(train.shape, test.shape)\n",
    "\n",
    "    def dropColumns(self) -> None:\n",
    "        name = ['TSH_measured', 'T3_measured', 'TT4_measured', \n",
    "                'T4U_measured', 'TBG' , 'FTI_measured','TBG_measured','TSH']\n",
    "        \n",
    "        self.data.drop(name, inplace=True, axis=1, errors=\"ignore\")\n",
    "        logger.info(f\"Columns are dropped from DataFrame : {name}\")\n",
    "    \n",
    "    def replaceWithNull(self) -> None:\n",
    "        try:\n",
    "            self.data.replace({'?':np.nan},inplace=True)\n",
    "            logger.info(\" ? is filled with np.nan values\")\n",
    "        except Exception as e:\n",
    "            logger.info(\"Error while replacing value with NaN \")\n",
    "            raise e\n",
    "        \n",
    "    def replaceCategorical(self) -> None:\n",
    "        # converting Sex column as F:0 and M:1\n",
    "        # rest f:0 and t:1\n",
    "        self.data[\"sex\"] = self.data[\"sex\"].map({'F':0, 'M':1})\n",
    "\n",
    "        for col in self.data.columns:\n",
    "            if len(self.data[col].unique())==2:\n",
    "                self.data[col] = self.data[col].map({'f':0,'t':1})\n",
    "\n",
    "        # creating dummies columns of referral source\n",
    "        self.data = pd.get_dummies(self.data, columns=['referral_source'], dtype='int')\n",
    "        \n",
    "        logger.info(\"replacement of categorical data into Numerical is completed\")\n",
    "\n",
    "    def labelEncoding(self) -> None:\n",
    "\n",
    "        # making Label Encoding object\n",
    "        lblEn = LabelEncoder()\n",
    "        # fitting Label encoding in class column\n",
    "        self.data[\"Class\"] = lblEn.fit_transform(self.data['Class'])\n",
    "\n",
    "        logger.info(\"Label Encoding is completed on Class columns\")\n",
    "        # saving  as  lable_encoding object as pickle\n",
    "\n",
    "        logger.info(\"Pickle file of label object is save in location : PATH \")\n",
    "    \n",
    "    def fill_na(self) -> None:\n",
    "        \n",
    "        # creating imputer object\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        col = self.data.columns\n",
    "        # applying imputer and getting np.array\n",
    "        self.data = np.round(imputer.fit_transform(self.data))\n",
    "        # converting array into dataframe\n",
    "        self.data = pd.DataFrame(data=self.data, columns=col)\n",
    "        logger.info(\" Empty NaN value is replaced using KNNImputer \")\n",
    "\n",
    "    def cap_data(self, series):\n",
    "        # creating lower percentile and upper percentile of outler data\n",
    "        lower = np.percentile(series ,5)\n",
    "        upper = np.percentile(series,95)\n",
    "        return np.clip(series,lower,upper)\n",
    "    \n",
    "    def apply_cap(self) -> None:\n",
    "        # this will apply Cap to Outliers in the following columns\n",
    "        name = ['age','T3','TT4','T4U','FTI']\n",
    "        self.data[name] = self.data[name].apply(self.cap_data)\n",
    "        logger.info(f\" Capping outlier completed in columns : {name}\")\n",
    "\n",
    "    def over_sampling(self) -> None:\n",
    "        \n",
    "        # smote object\n",
    "        rdsmple = RandomOverSampler()\n",
    "        X = self.data.drop([\"Class\"],axis=1)\n",
    "        y = self.data[\"Class\"]\n",
    "        col_name = X.columns\n",
    "\n",
    "        # Applying Smote and it will return two numpy series\n",
    "        X, y = rdsmple.fit_resample(X,y)\n",
    "\n",
    "        # converting oversampled data into dataframe\n",
    "        self.data = pd.concat([pd.DataFrame(X, columns=col_name),\n",
    "                               pd.Series(y, name = 'Class')], axis=1)\n",
    "        logger.info(\"Data Over Sampling is completed !!!!\")\n",
    "\n",
    "\n",
    "\n",
    "    def run(self) -> None:\n",
    "        self.dropColumns()\n",
    "        self.replaceWithNull()\n",
    "        self.replaceCategorical()\n",
    "        self.labelEncoding()\n",
    "        self.fill_na()\n",
    "        self.apply_cap()\n",
    "        self.over_sampling()\n",
    "        self.train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_transformation(config : ConfigurationManager) -> None:\n",
    "    obj = DataTransformation(config=config)\n",
    "    obj.dropColumns()\n",
    "    obj.replaceWithNull()\n",
    "    obj.replaceCategorical()\n",
    "    obj.labelEncoding()\n",
    "    obj.fill_na()\n",
    "    obj.apply_cap()\n",
    "    obj.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-03 01:02:39,432 : INFO : common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-04-03 01:02:39,434 : INFO : common : yaml file: params.yaml loaded successfully]\n",
      "[2024-04-03 01:02:39,438 : INFO : common : yaml file: schema.yaml loaded successfully]\n",
      "[2024-04-03 01:02:39,439 : INFO : common : created directory at: artifacts]\n",
      "[2024-04-03 01:02:39,440 : INFO : common : created directory at: artifacts/data_transformation]\n",
      "[2024-04-03 01:02:39,450 : INFO : 2868054964 : Columns are dropped from DataFrame : ['TSH_measured', 'T3_measured', 'TT4_measured', 'T4U_measured', 'TBG', 'FTI_measured', 'TBG_measured', 'TSH']]\n",
      "[2024-04-03 01:02:39,456 : INFO : 2868054964 :  ? is filled with np.nan values]\n",
      "[2024-04-03 01:02:39,474 : INFO : 2868054964 : replacement of categorical data into Numerical is completed]\n",
      "[2024-04-03 01:02:39,476 : INFO : 2868054964 : Label Encoding is completed on Class columns]\n",
      "[2024-04-03 01:02:39,477 : INFO : 2868054964 : Pickle file of label object is save in location : PATH ]\n",
      "[2024-04-03 01:02:39,782 : INFO : 2868054964 :  Empty NaN value is replaced using KNNImputer ]\n",
      "[2024-04-03 01:02:39,789 : INFO : 2868054964 :  Capping outlier completed in columns : ['age', 'T3', 'TT4', 'T4U', 'FTI']]\n",
      "[2024-04-03 01:02:39,807 : INFO : 2868054964 : Data Over Sampling is completed !!!!]\n",
      "[2024-04-03 01:02:39,913 : INFO : 2868054964 : Splited data into test and train sets]\n",
      "[2024-04-03 01:02:39,913 : INFO : 2868054964 : train shape:(11139, 26)]\n",
      "[2024-04-03 01:02:39,914 : INFO : 2868054964 : Test shape: (2785, 26)]\n",
      "(11139, 26) (2785, 26)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.run()\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
